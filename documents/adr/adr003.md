# ADR 003: Implementação de Cache Distribuído (Redis)

## Contexto
O sistema apresenta um perfil de tráfego com **alta proporção de leitura** (100:1). Funcionalidades como listagem de filmes e visualização de assentos geram carga excessiva no banco de dados relacional (PostgreSQL).

Riscos identificados:
* **Gargalo:** O banco de dados pode travar em dias de estreias de grandes filmes.
* **Latência:** O tempo de resposta para carregar o mapa de assentos está acima do aceitável (>200ms).
* **Custo:** Escalar o banco verticalmente é inviável financeiramente no momento.

## 2. Decisão
Implementação de uma camada de **Cache Distribuído** utilizando **Redis**, integrado via `@nestjs/cache-manager`.

### Detalhes da Implementação:
* **Escopo:** Microsserviços de *Catalog* e *Session*.
* **Estratégia:** *Cache-Aside* (Lazy Loading). A aplicação busca no Redis; se der *miss*, busca no banco e popula o cache.
* **TTL (Time-to-Live):**
    * *Filmes:* Longo (1 hora).
    * *Assentos:* Curto (10 segundos) ou invalidação por evento.

## 3. Alternativas Rejeitadas
**Cache em Memória (In-Memory / RAM Local)**
* **Motivo da Rejeição:** Incompatível com a arquitetura de microsserviços escalável. Se tivermos múltiplas réplicas do mesmo serviço, o cache local causaria inconsistência de dados entre os containers.

## 4. Consequências

### Benefícios
* Redução na carga de leitura direta no PostgreSQL.
* Tempo de resposta da API reduzido para ordem de **milissegundos**.
* Maior resiliência do sistema durante picos de tráfego.

### Riscos e Mitigações
* **Consistência Eventual:** O usuário pode ver um assento livre que acabou de ser vendido.
* **Mitigação:** A transação de compra (`POST /tickets`) ignora o cache e valida a disponibilidade diretamente no banco de dados antes de confirmar.